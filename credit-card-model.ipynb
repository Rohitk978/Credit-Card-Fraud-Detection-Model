{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"fraudTrain.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b933dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab08949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['first','last','gender','job','street','dob'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de586d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4dd1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0','trans_num'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import TargetEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cedef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['amt','city_pop']:\n",
    "    upper_limit = df[col].quantile(0.99)\n",
    "    df[col] = df[col].clip(upper=df[col].quantile(0.99))\n",
    "    \n",
    "    valid_lat =(-90,90)\n",
    "    valid_long =(-180,180)\n",
    "    df = df[\n",
    "        (df['lat'].between(*valid_lat)) &\n",
    "        (df['long'].between(*valid_lat)) &\n",
    "        (df['merch_lat'].between(*valid_lat)) &\n",
    "        (df['merch_long'].between(*valid_lat)) \n",
    "    ]\n",
    "    \n",
    "    df = df[df['city_pop'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse trans_date_trans_time to datetime\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "\n",
    "# Validate consistency with unix_time\n",
    "df['unix_time_converted'] = pd.to_datetime(df['unix_time'], unit='s')\n",
    "inconsistent = df[\n",
    "    abs((df['trans_date_trans_time'] - df['unix_time_converted']).dt.total_seconds()) > 60\n",
    "]\n",
    "if len(inconsistent) > 0:\n",
    "    print(f\"Found {len(inconsistent)} inconsistent timestamps. Consider dropping or correcting.\")\n",
    "\n",
    "# Drop unix_time if redundant\n",
    "df = df.drop(columns=['unix_time', 'unix_time_converted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Haversine distance\n",
    "def haversine_distance(row):\n",
    "    customer = (row['lat'], row['long'])\n",
    "    merchant = (row['merch_lat'], row['merch_long'])\n",
    "    return geodesic(customer, merchant).kilometers\n",
    "\n",
    "df['distance_km'] = df.apply(haversine_distance, axis=1)\n",
    "\n",
    "# Flag large distances (e.g., >100 km)\n",
    "df['large_distance'] = (df['distance_km'] > 100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef233723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target encoding for high-cardinality columns\n",
    "encoder = TargetEncoder(cols=['merchant', 'city', 'state', 'zip'])\n",
    "df[['merchant_encoded', 'city_encoded', 'state_encoded', 'zip_encoded']] = encoder.fit_transform(\n",
    "    df[['merchant', 'city', 'state', 'zip']], df['is_fraud']\n",
    ")\n",
    "\n",
    "# One-hot encoding for category\n",
    "df = pd.get_dummies(df, columns=['category'], prefix='cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform skewed features\n",
    "df['amt_log'] = np.log1p(df['amt'])\n",
    "df['city_pop_log'] = np.log1p(df['city_pop'])\n",
    "\n",
    "# Standardize numerical features\n",
    "numerical_cols = ['amt_log', 'city_pop_log', 'lat', 'long', 'merch_lat', 'merch_long', 'distance_km']\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount deviation from card's average\n",
    "df['avg_amt_per_cc'] = df.groupby('cc_num')['amt'].transform('mean')\n",
    "df['amt_deviation'] = df['amt'] - df['avg_amt_per_cc']\n",
    "df['amt_deviation_flag'] = (df['amt_deviation'].abs() > df['avg_amt_per_cc']).astype(int)\n",
    "\n",
    "# Already created large_distance in Geographical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573af2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in ['city','state','cat_misc_pos','cat_personal_care','cat_shopping_net','cat_shopping_pos','cat_travel']:\n",
    "    df[cols] = le.fit_transform(df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['merchant'] = le.fit_transform(df['merchant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97174739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amt_deviation_flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e64841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab98b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['city_pop_log','avg_amt_per_cc','avg_amt_per_cc']:\n",
    "    df[i]= ss.fit_transform(df[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('amt_deviation_flag',axis=1)\n",
    "y = df['amt_deviation_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bea4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert trans_date_trans_time to Unix timestamp (seconds since epoch)\n",
    "if 'trans_date_trans_time' in x.columns:\n",
    "    x['trans_date_trans_time'] = x['trans_date_trans_time'].astype(np.int64) // 10**9  # Convert to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518dda78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Identify remaining categorical columns\n",
    "categorical_cols = x.select_dtypes(include=['object', 'string']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    print(\"Encoding categorical columns:\", categorical_cols)\n",
    "    encoder = TargetEncoder(cols=categorical_cols)\n",
    "    x[categorical_cols] = encoder.fit_transform(x[categorical_cols], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_cols = x.select_dtypes(include=[np.number]).columns\n",
    "x = x[numeric_cols]\n",
    "\n",
    "# Check for non-numeric columns\n",
    "non_numeric_cols = x.select_dtypes(exclude=[np.number]).columns\n",
    "if len(non_numeric_cols) > 0:\n",
    "    print(\"Non-numeric columns remaining:\", non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb64844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to_numpy().astype(np.float32)\n",
    "y = y.to_numpy().astype(np.int32)\n",
    "\n",
    "# Step 6: Convert to tensors\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b75ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Convert x and y to NumPy arrays if they are tensors\n",
    "if isinstance(x, tf.Tensor):\n",
    "    x = x.numpy()\n",
    "if isinstance(y, tf.Tensor):\n",
    "    y = y.numpy()\n",
    "\n",
    "# Verify types after conversion\n",
    "print(\"Type of x after conversion:\", type(x))\n",
    "print(\"Type of y after conversion:\", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8768172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout,BatchNormalization\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e143bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128,input_dim=x_train.shape[1],activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1,activation='sigmoid')\n",
    "    \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,batch_size=70,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e068367f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3db918fd-5cfc-4ad4-a2a0-35ec19430491/assets\n",
      "Model saved successfully to 'FNN.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "try:\n",
    "    joblib.dump(model, 'FNN.pkl')\n",
    "    print(\"Model saved successfully to 'FNN.pkl'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving files: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f087bb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikitenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
